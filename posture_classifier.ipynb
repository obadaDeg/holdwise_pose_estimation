{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this Application write this in your terminal:\n",
    "\n",
    "```py -3.10 -m venv myenv```\n",
    "\n",
    "```.\\myenv\\Scripts\\Activate```\n",
    "\n",
    "select the kernal to be myenv (Python 3.10.0)\n",
    "\n",
    "```py --version``` insure this version is 3.10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.0\n"
     ]
    }
   ],
   "source": [
    "!py --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **this cell could take some time to run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow is already installed.\n",
      "tensorflow-hub not found. Installing...\n",
      "tensorflow-hub installed successfully.\n",
      "numpy is already installed.\n",
      "matplotlib is already installed.\n",
      "pandas is already installed.\n",
      "cv2 is already installed.\n",
      "keras is already installed.\n",
      "pillow not found. Installing...\n",
      "pillow installed successfully.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import importlib\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor \n",
    "    \n",
    "# Define the libraries and their pip install commands\n",
    "libraries = {\n",
    "    \"tensorflow\": \"pip install tensorflow\",\n",
    "    \"tensorflow-hub\": \"pip install tensorflow-hub\",\n",
    "    \"numpy\": \"pip install numpy\",\n",
    "    \"matplotlib\": \"pip install matplotlib\",\n",
    "    \"pandas\": \"pip install pandas\",\n",
    "    \"cv2\": \"pip install opencv-python\", \n",
    "    \"keras\": \"pip install keras\",\n",
    "    \"pillow\": \"pip install pillow\",\n",
    "}\n",
    "\n",
    "for library, command in libraries.items():\n",
    "    try:\n",
    "        importlib.import_module(library)\n",
    "        print(f\"{library} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"{library} not found. Installing...\")\n",
    "        try:\n",
    "            subprocess.run(command.split(), check=True)\n",
    "            print(f\"{library} installed successfully.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Failed to install {library}. Error: {e}\")\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import models, layers, applications, utils, preprocessing\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frames(video_path, output_folder, frame_rate=1):\n",
    "    \"\"\"\n",
    "    Extracts frames from a video at a specified frame rate.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the video file.\n",
    "        output_folder (str): Folder to save the extracted frames.\n",
    "        frame_rate (int): Number of frames to save per second of video.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if frame_rate <= 0:\n",
    "        logging.error(\"Error: Frame rate must be a positive integer.\")\n",
    "        return\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        logging.error(f\"Error: Could not open video file '{video_path}'.\")\n",
    "        return\n",
    "\n",
    "    # Get the video's frame rate and total number of frames\n",
    "    video_fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "    if video_fps <= 0:\n",
    "        logging.error(\"Error: Invalid video FPS. Please check the video file.\")\n",
    "        video.release()\n",
    "        return\n",
    "\n",
    "    if frame_rate > video_fps:\n",
    "        logging.warning(f\"Warning: Frame rate ({frame_rate}) exceeds video FPS ({video_fps}). Adjusting to match video FPS.\")\n",
    "        frame_rate = video_fps\n",
    "\n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    logging.info(f\"Video FPS: {video_fps}, Total Frames: {frame_count}\")\n",
    "\n",
    "    # Calculate the frame interval for the desired frame rate\n",
    "    frame_interval = video_fps // frame_rate\n",
    "\n",
    "    # Extract and save frames\n",
    "    frame_idx = 0\n",
    "    saved_frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break  # End of video\n",
    "\n",
    "        # Save the frame at the specified interval\n",
    "        if frame_idx % frame_interval == 0:\n",
    "            frame_filename = os.path.join(output_folder, f\"frame_{saved_frame_idx:04d}.jpg\")\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            saved_frame_idx += 1\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    # Release the video capture object\n",
    "    video.release()\n",
    "\n",
    "    if saved_frame_idx == 0:\n",
    "        logging.warning(\"No frames were saved. Adjust the frame rate and try again.\")\n",
    "    else:\n",
    "        logging.info(f\"{saved_frame_idx} frames saved to '{output_folder}'.\")\n",
    "        \n",
    "    return saved_frame_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_extraction_folders = [\n",
    "    \"workspace/good_pose\",\n",
    "    \"workspace/bad_pose\",\n",
    "    \"workspace/cant_determine\"\n",
    "]\n",
    "\n",
    "\n",
    "def process_session(session_path, label, output_dir, frame_rate=1):\n",
    "    \"\"\"\n",
    "    Processes a single session folder, extracting frames and mapping to sensor data.\n",
    "    \"\"\"\n",
    "    video_path, json_path = None, None\n",
    "\n",
    "    for file_name in os.listdir(session_path):\n",
    "        file_path = os.path.join(session_path, file_name)\n",
    "        lower = file_name.lower()\n",
    "        if lower.endswith('.mp4'):\n",
    "            video_path = file_path\n",
    "        elif lower.endswith('.json'):\n",
    "            json_path = file_path\n",
    "\n",
    "    if not video_path or not os.path.exists(video_path):\n",
    "        logging.warning(f\"No valid video found in: {session_path}\")\n",
    "        return\n",
    "    if not json_path or not os.path.exists(json_path):\n",
    "        logging.warning(f\"No valid JSON file found in: {session_path}\")\n",
    "        return\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        sensor_data = json.load(f)\n",
    "\n",
    "    gyro_list = sensor_data.get(\"gyroscopeData\", [])\n",
    "    accel_list = sensor_data.get(\"accelerometerData\", [])\n",
    "\n",
    "    session_name = Path(session_path).name\n",
    "    session_output = os.path.join(output_dir, label, session_name)\n",
    "    os.makedirs(session_output, exist_ok=True)\n",
    "\n",
    "    saved_frames = video_to_frames(video_path, session_output, frame_rate)\n",
    "    if saved_frames == 0:\n",
    "        logging.warning(\"No frames were extracted; skipping sensor mapping.\")\n",
    "        return\n",
    "\n",
    "    if not gyro_list or not accel_list:\n",
    "        logging.warning(\"Missing sensor data in JSON; skipping sensor mapping.\")\n",
    "        return\n",
    "\n",
    "    frame_files = sorted([f for f in os.listdir(session_output) if f.lower().endswith('.jpg')])\n",
    "    csv_path = os.path.join(session_output, \"frame_sensor_mapping.csv\")\n",
    "\n",
    "    with open(csv_path, 'w') as csv_file:\n",
    "        csv_file.write(\"frame_file,frame_idx,sensor_idx,gyro_x,gyro_y,gyro_z,accel_x,accel_y,accel_z\\n\")\n",
    "        M = saved_frames\n",
    "        N = len(gyro_list)\n",
    "        L = len(accel_list)\n",
    "\n",
    "        for i, frame_file in enumerate(frame_files):\n",
    "            gyro_idx = int((i / M) * N)\n",
    "            accel_idx = int((i / M) * L)\n",
    "\n",
    "            gyro_data = gyro_list[gyro_idx]\n",
    "            accel_data = accel_list[accel_idx]\n",
    "\n",
    "            csv_file.write(\n",
    "                f\"{frame_file},{i},{gyro_idx},\"\n",
    "                f\"{gyro_data.get('x', 0)},{gyro_data.get('y', 0)},{gyro_data.get('z', 0)},\"\n",
    "                f\"{accel_data.get('x', 0)},{accel_data.get('y', 0)},{accel_data.get('z', 0)}\\n\"\n",
    "            )\n",
    "\n",
    "            # old_path = os.path.join(session_output, frame_file)\n",
    "            # base, ext = os.path.splitext(frame_file)\n",
    "            # new_filename = f\"{base}_sensor_{gyro_idx}{ext}\"\n",
    "            # new_path = os.path.join(session_output, new_filename)\n",
    "            # os.rename(old_path, new_path)\n",
    "\n",
    "    logging.info(f\"Frame-to-sensor mapping complete for: {session_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 16:04:00,754 - INFO - Video FPS: 30, Total Frames: 525\n",
      "2025-01-08 16:04:00,766 - INFO - Video FPS: 29, Total Frames: 1217\n",
      "2025-01-08 16:04:00,790 - INFO - Video FPS: 29, Total Frames: 751\n",
      "2025-01-08 16:04:04,841 - INFO - 18 frames saved to 'extracted_frames\\workspace/bad_pose\\10'.\n",
      "2025-01-08 16:04:04,845 - WARNING - Missing sensor data in JSON; skipping sensor mapping.\n",
      "2025-01-08 16:04:04,905 - INFO - Video FPS: 29, Total Frames: 311\n",
      "2025-01-08 16:04:06,659 - INFO - 26 frames saved to 'extracted_frames\\workspace/good_pose\\1'.\n",
      "2025-01-08 16:04:06,664 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\1\n",
      "2025-01-08 16:04:06,716 - INFO - Video FPS: 29, Total Frames: 667\n",
      "2025-01-08 16:04:07,311 - INFO - 11 frames saved to 'extracted_frames\\workspace/bad_pose\\12'.\n",
      "2025-01-08 16:04:07,316 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\12\n",
      "2025-01-08 16:04:07,367 - INFO - Video FPS: 29, Total Frames: 1018\n",
      "2025-01-08 16:04:10,273 - INFO - 42 frames saved to 'extracted_frames\\workspace/cant_determine\\14'.\n",
      "2025-01-08 16:04:10,277 - INFO - Frame-to-sensor mapping complete for: workspace\\cant_determine\\14\n",
      "2025-01-08 16:04:10,322 - INFO - Video FPS: 29, Total Frames: 391\n",
      "2025-01-08 16:04:12,415 - INFO - 23 frames saved to 'extracted_frames\\workspace/good_pose\\11'.\n",
      "2025-01-08 16:04:12,417 - WARNING - Missing sensor data in JSON; skipping sensor mapping.\n",
      "2025-01-08 16:04:12,462 - INFO - Video FPS: 29, Total Frames: 1246\n",
      "2025-01-08 16:04:13,359 - INFO - 14 frames saved to 'extracted_frames\\workspace/cant_determine\\24'.\n",
      "2025-01-08 16:04:13,363 - INFO - Frame-to-sensor mapping complete for: workspace\\cant_determine\\24\n",
      "2025-01-08 16:04:13,419 - INFO - Video FPS: 29, Total Frames: 1770\n",
      "2025-01-08 16:04:15,376 - INFO - 36 frames saved to 'extracted_frames\\workspace/bad_pose\\13'.\n",
      "2025-01-08 16:04:15,379 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\13\n",
      "2025-01-08 16:04:15,427 - INFO - Video FPS: 29, Total Frames: 442\n",
      "2025-01-08 16:04:18,909 - INFO - 16 frames saved to 'extracted_frames\\workspace/bad_pose\\16'.\n",
      "2025-01-08 16:04:18,912 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\16\n",
      "2025-01-08 16:04:18,971 - INFO - Video FPS: 29, Total Frames: 478\n",
      "2025-01-08 16:04:22,955 - INFO - 43 frames saved to 'extracted_frames\\workspace/good_pose\\15'.\n",
      "2025-01-08 16:04:22,962 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\15\n",
      "2025-01-08 16:04:23,022 - INFO - Video FPS: 29, Total Frames: 826\n",
      "2025-01-08 16:04:23,380 - INFO - 17 frames saved to 'extracted_frames\\workspace/bad_pose\\18'.\n",
      "2025-01-08 16:04:23,384 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\18\n",
      "2025-01-08 16:04:23,435 - INFO - Video FPS: 29, Total Frames: 1016\n",
      "2025-01-08 16:04:28,143 - INFO - 62 frames saved to 'extracted_frames\\workspace/cant_determine\\51'.\n",
      "2025-01-08 16:04:28,149 - INFO - Frame-to-sensor mapping complete for: workspace\\cant_determine\\51\n",
      "2025-01-08 16:04:28,154 - WARNING - No valid video found in: workspace\\cant_determine\\missing data\n",
      "2025-01-08 16:04:29,615 - INFO - 29 frames saved to 'extracted_frames\\workspace/good_pose\\17'.\n",
      "2025-01-08 16:04:29,618 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\17\n",
      "2025-01-08 16:04:29,657 - INFO - Video FPS: 29, Total Frames: 549\n",
      "2025-01-08 16:04:31,036 - INFO - 36 frames saved to 'extracted_frames\\workspace/bad_pose\\19'.\n",
      "2025-01-08 16:04:31,038 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\19\n",
      "2025-01-08 16:04:31,076 - INFO - Video FPS: 29, Total Frames: 1697\n",
      "2025-01-08 16:04:33,176 - INFO - 19 frames saved to 'extracted_frames\\workspace/good_pose\\2'.\n",
      "2025-01-08 16:04:33,179 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\2\n",
      "2025-01-08 16:04:33,216 - INFO - Video FPS: 29, Total Frames: 946\n",
      "2025-01-08 16:04:39,004 - INFO - 33 frames saved to 'extracted_frames\\workspace/good_pose\\21'.\n",
      "2025-01-08 16:04:39,008 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\21\n",
      "2025-01-08 16:04:39,055 - INFO - Video FPS: 30, Total Frames: 56\n",
      "2025-01-08 16:04:39,437 - INFO - 2 frames saved to 'extracted_frames\\workspace/good_pose\\23'.\n",
      "2025-01-08 16:04:39,440 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\23\n",
      "2025-01-08 16:04:39,494 - INFO - Video FPS: 29, Total Frames: 358\n",
      "2025-01-08 16:04:41,579 - INFO - 59 frames saved to 'extracted_frames\\workspace/bad_pose\\20'.\n",
      "2025-01-08 16:04:41,583 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\20\n",
      "2025-01-08 16:04:41,626 - INFO - Video FPS: 29, Total Frames: 319\n",
      "2025-01-08 16:04:41,988 - INFO - 13 frames saved to 'extracted_frames\\workspace/good_pose\\25'.\n",
      "2025-01-08 16:04:41,992 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\25\n",
      "2025-01-08 16:04:42,059 - INFO - Video FPS: 29, Total Frames: 7672\n",
      "2025-01-08 16:04:43,994 - INFO - 11 frames saved to 'extracted_frames\\workspace/bad_pose\\26'.\n",
      "2025-01-08 16:04:43,996 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\26\n",
      "2025-01-08 16:04:44,058 - INFO - Video FPS: 26, Total Frames: 53\n",
      "2025-01-08 16:04:44,399 - INFO - 3 frames saved to 'extracted_frames\\workspace/bad_pose\\29'.\n",
      "2025-01-08 16:04:44,402 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\29\n",
      "2025-01-08 16:04:44,459 - INFO - Video FPS: 29, Total Frames: 261\n",
      "2025-01-08 16:04:46,229 - INFO - 9 frames saved to 'extracted_frames\\workspace/bad_pose\\3'.\n",
      "2025-01-08 16:04:46,232 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\3\n",
      "2025-01-08 16:04:46,291 - INFO - Video FPS: 26, Total Frames: 53\n",
      "2025-01-08 16:04:46,630 - INFO - 3 frames saved to 'extracted_frames\\workspace/bad_pose\\38'.\n",
      "2025-01-08 16:04:46,632 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\38\n",
      "2025-01-08 16:04:46,681 - INFO - Video FPS: 29, Total Frames: 7473\n",
      "2025-01-08 16:05:29,730 - INFO - 265 frames saved to 'extracted_frames\\workspace/good_pose\\30'.\n",
      "2025-01-08 16:05:29,735 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\30\n",
      "2025-01-08 16:05:29,767 - INFO - Video FPS: 29, Total Frames: 146\n",
      "2025-01-08 16:05:30,586 - INFO - 6 frames saved to 'extracted_frames\\workspace/good_pose\\32'.\n",
      "2025-01-08 16:05:30,589 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\32\n",
      "2025-01-08 16:05:30,632 - INFO - Video FPS: 29, Total Frames: 355\n",
      "2025-01-08 16:05:32,163 - INFO - 258 frames saved to 'extracted_frames\\workspace/bad_pose\\39'.\n",
      "2025-01-08 16:05:32,168 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\39\n",
      "2025-01-08 16:05:32,216 - INFO - Video FPS: 29, Total Frames: 5596\n",
      "2025-01-08 16:05:32,783 - INFO - 13 frames saved to 'extracted_frames\\workspace/good_pose\\33'.\n",
      "2025-01-08 16:05:32,786 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\33\n",
      "2025-01-08 16:05:32,849 - INFO - Video FPS: 29, Total Frames: 698\n",
      "2025-01-08 16:05:36,999 - INFO - 25 frames saved to 'extracted_frames\\workspace/good_pose\\34'.\n",
      "2025-01-08 16:05:37,002 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\34\n",
      "2025-01-08 16:05:37,047 - INFO - Video FPS: 29, Total Frames: 7672\n",
      "2025-01-08 16:06:03,423 - INFO - 193 frames saved to 'extracted_frames\\workspace/bad_pose\\42'.\n",
      "2025-01-08 16:06:03,429 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\42\n",
      "2025-01-08 16:06:03,478 - INFO - Video FPS: 29, Total Frames: 2839\n",
      "2025-01-08 16:06:19,465 - INFO - 98 frames saved to 'extracted_frames\\workspace/bad_pose\\44'.\n",
      "2025-01-08 16:06:19,468 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\44\n",
      "2025-01-08 16:06:19,500 - INFO - Video FPS: 29, Total Frames: 154\n",
      "2025-01-08 16:06:20,286 - INFO - 265 frames saved to 'extracted_frames\\workspace/good_pose\\37'.\n",
      "2025-01-08 16:06:20,292 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\37\n",
      "2025-01-08 16:06:20,330 - INFO - Video FPS: 29, Total Frames: 94\n",
      "2025-01-08 16:06:20,438 - INFO - 6 frames saved to 'extracted_frames\\workspace/bad_pose\\45'.\n",
      "2025-01-08 16:06:20,440 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\45\n",
      "2025-01-08 16:06:20,480 - INFO - Video FPS: 29, Total Frames: 711\n",
      "2025-01-08 16:06:20,888 - INFO - 4 frames saved to 'extracted_frames\\workspace/good_pose\\4'.\n",
      "2025-01-08 16:06:20,890 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\4\n",
      "2025-01-08 16:06:20,939 - INFO - Video FPS: 29, Total Frames: 4684\n",
      "2025-01-08 16:06:24,781 - INFO - 25 frames saved to 'extracted_frames\\workspace/bad_pose\\46'.\n",
      "2025-01-08 16:06:24,783 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\46\n",
      "2025-01-08 16:06:24,826 - INFO - Video FPS: 29, Total Frames: 64\n",
      "2025-01-08 16:06:25,158 - INFO - 3 frames saved to 'extracted_frames\\workspace/bad_pose\\47'.\n",
      "2025-01-08 16:06:25,160 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\47\n",
      "2025-01-08 16:06:25,193 - INFO - Video FPS: 29, Total Frames: 316\n",
      "2025-01-08 16:06:27,133 - INFO - 11 frames saved to 'extracted_frames\\workspace/bad_pose\\49'.\n",
      "2025-01-08 16:06:27,135 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\49\n",
      "2025-01-08 16:06:27,175 - INFO - Video FPS: 29, Total Frames: 529\n",
      "2025-01-08 16:06:30,460 - INFO - 19 frames saved to 'extracted_frames\\workspace/bad_pose\\50'.\n",
      "2025-01-08 16:06:30,462 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\50\n",
      "2025-01-08 16:06:30,502 - INFO - Video FPS: 27, Total Frames: 70\n",
      "2025-01-08 16:06:30,954 - INFO - 3 frames saved to 'extracted_frames\\workspace/bad_pose\\52'.\n",
      "2025-01-08 16:06:30,956 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\52\n",
      "2025-01-08 16:06:30,991 - INFO - Video FPS: 30, Total Frames: 3169\n",
      "2025-01-08 16:06:48,399 - INFO - 162 frames saved to 'extracted_frames\\workspace/good_pose\\40'.\n",
      "2025-01-08 16:06:48,405 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\40\n",
      "2025-01-08 16:06:48,454 - INFO - Video FPS: 29, Total Frames: 108\n",
      "2025-01-08 16:06:49,060 - INFO - 4 frames saved to 'extracted_frames\\workspace/good_pose\\41'.\n",
      "2025-01-08 16:06:49,062 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\41\n",
      "2025-01-08 16:06:49,095 - INFO - Video FPS: 29, Total Frames: 459\n",
      "2025-01-08 16:06:49,130 - INFO - 106 frames saved to 'extracted_frames\\workspace/bad_pose\\54'.\n",
      "2025-01-08 16:06:49,135 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\54\n",
      "2025-01-08 16:06:49,215 - INFO - Video FPS: 29, Total Frames: 5171\n",
      "2025-01-08 16:06:51,951 - INFO - 16 frames saved to 'extracted_frames\\workspace/good_pose\\48'.\n",
      "2025-01-08 16:06:51,953 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\48\n",
      "2025-01-08 16:06:51,987 - INFO - Video FPS: 30, Total Frames: 2567\n",
      "2025-01-08 16:07:07,475 - INFO - 86 frames saved to 'extracted_frames\\workspace/good_pose\\53'.\n",
      "2025-01-08 16:07:07,479 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\53\n",
      "2025-01-08 16:07:07,533 - INFO - Video FPS: 29, Total Frames: 1976\n",
      "2025-01-08 16:07:19,301 - INFO - 69 frames saved to 'extracted_frames\\workspace/good_pose\\57'.\n",
      "2025-01-08 16:07:19,307 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\57\n",
      "2025-01-08 16:07:19,350 - INFO - Video FPS: 30, Total Frames: 23\n",
      "2025-01-08 16:07:19,489 - INFO - 1 frames saved to 'extracted_frames\\workspace/good_pose\\58'.\n",
      "2025-01-08 16:07:19,490 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\58\n",
      "2025-01-08 16:07:19,522 - INFO - Video FPS: 30, Total Frames: 2015\n",
      "2025-01-08 16:07:19,701 - INFO - 179 frames saved to 'extracted_frames\\workspace/bad_pose\\55'.\n",
      "2025-01-08 16:07:19,707 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\55\n",
      "2025-01-08 16:07:19,812 - INFO - Video FPS: 29, Total Frames: 1867\n",
      "2025-01-08 16:07:30,054 - INFO - 65 frames saved to 'extracted_frames\\workspace/bad_pose\\56'.\n",
      "2025-01-08 16:07:30,058 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\56\n",
      "2025-01-08 16:07:30,098 - INFO - Video FPS: 29, Total Frames: 1859\n",
      "2025-01-08 16:07:30,509 - INFO - 68 frames saved to 'extracted_frames\\workspace/good_pose\\62'.\n",
      "2025-01-08 16:07:30,513 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\62\n",
      "2025-01-08 16:07:30,565 - INFO - Video FPS: 29, Total Frames: 1062\n",
      "2025-01-08 16:07:36,376 - INFO - 37 frames saved to 'extracted_frames\\workspace/good_pose\\63'.\n",
      "2025-01-08 16:07:36,379 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\63\n",
      "2025-01-08 16:07:36,427 - INFO - Video FPS: 29, Total Frames: 2911\n",
      "2025-01-08 16:07:40,328 - INFO - 65 frames saved to 'extracted_frames\\workspace/bad_pose\\59'.\n",
      "2025-01-08 16:07:40,332 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\59\n",
      "2025-01-08 16:07:40,371 - INFO - Video FPS: 29, Total Frames: 1930\n",
      "2025-01-08 16:07:52,460 - INFO - 67 frames saved to 'extracted_frames\\workspace/bad_pose\\61'.\n",
      "2025-01-08 16:07:52,463 - INFO - Frame-to-sensor mapping complete for: workspace\\bad_pose\\61\n",
      "2025-01-08 16:07:52,503 - INFO - Video FPS: 30, Total Frames: 279\n",
      "2025-01-08 16:07:54,395 - INFO - 101 frames saved to 'extracted_frames\\workspace/good_pose\\64'.\n",
      "2025-01-08 16:07:54,399 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\64\n",
      "2025-01-08 16:07:54,441 - INFO - 10 frames saved to 'extracted_frames\\workspace/bad_pose\\9'.\n",
      "2025-01-08 16:07:54,443 - WARNING - Missing sensor data in JSON; skipping sensor mapping.\n",
      "2025-01-08 16:07:54,448 - INFO - Video FPS: 29, Total Frames: 5643\n",
      "2025-01-08 16:08:18,148 - INFO - 195 frames saved to 'extracted_frames\\workspace/good_pose\\65'.\n",
      "2025-01-08 16:08:18,152 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\65\n",
      "2025-01-08 16:08:18,195 - INFO - Video FPS: 29, Total Frames: 5864\n",
      "2025-01-08 16:08:43,342 - INFO - 203 frames saved to 'extracted_frames\\workspace/good_pose\\66'.\n",
      "2025-01-08 16:08:43,346 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\66\n",
      "2025-01-08 16:08:43,386 - INFO - Video FPS: 29, Total Frames: 12475\n",
      "2025-01-08 16:09:40,737 - INFO - 431 frames saved to 'extracted_frames\\workspace/good_pose\\67'.\n",
      "2025-01-08 16:09:40,743 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\67\n",
      "2025-01-08 16:09:40,773 - INFO - Video FPS: 29, Total Frames: 160\n",
      "2025-01-08 16:09:41,627 - INFO - 6 frames saved to 'extracted_frames\\workspace/good_pose\\68'.\n",
      "2025-01-08 16:09:41,630 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\68\n",
      "2025-01-08 16:09:41,694 - INFO - Video FPS: 29, Total Frames: 1793\n",
      "2025-01-08 16:09:50,884 - INFO - 62 frames saved to 'extracted_frames\\workspace/good_pose\\69'.\n",
      "2025-01-08 16:09:50,887 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\69\n",
      "2025-01-08 16:09:50,991 - INFO - Video FPS: 29, Total Frames: 633\n",
      "2025-01-08 16:09:53,770 - INFO - 22 frames saved to 'extracted_frames\\workspace/good_pose\\7'.\n",
      "2025-01-08 16:09:53,772 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\7\n",
      "2025-01-08 16:09:53,801 - INFO - Video FPS: 29, Total Frames: 2239\n",
      "2025-01-08 16:10:03,550 - INFO - 78 frames saved to 'extracted_frames\\workspace/good_pose\\70'.\n",
      "2025-01-08 16:10:03,556 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\70\n",
      "2025-01-08 16:10:03,608 - INFO - Video FPS: 30, Total Frames: 2430\n",
      "2025-01-08 16:10:13,879 - INFO - 81 frames saved to 'extracted_frames\\workspace/good_pose\\71'.\n",
      "2025-01-08 16:10:13,882 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\71\n",
      "2025-01-08 16:10:13,917 - INFO - Video FPS: 29, Total Frames: 2066\n",
      "2025-01-08 16:10:22,653 - INFO - 72 frames saved to 'extracted_frames\\workspace/good_pose\\72'.\n",
      "2025-01-08 16:10:22,655 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\72\n",
      "2025-01-08 16:10:22,691 - INFO - Video FPS: 30, Total Frames: 2196\n",
      "2025-01-08 16:10:31,511 - INFO - 74 frames saved to 'extracted_frames\\workspace/good_pose\\73'.\n",
      "2025-01-08 16:10:31,514 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\73\n",
      "2025-01-08 16:10:31,553 - INFO - Video FPS: 30, Total Frames: 3111\n",
      "2025-01-08 16:10:44,616 - INFO - 104 frames saved to 'extracted_frames\\workspace/good_pose\\74'.\n",
      "2025-01-08 16:10:44,620 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\74\n",
      "2025-01-08 16:10:44,673 - INFO - Video FPS: 30, Total Frames: 1933\n",
      "2025-01-08 16:10:52,750 - INFO - 65 frames saved to 'extracted_frames\\workspace/good_pose\\75'.\n",
      "2025-01-08 16:10:52,752 - INFO - Frame-to-sensor mapping complete for: workspace\\good_pose\\75\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"extracted_frames\"\n",
    "# frame_rate = 30\n",
    "frame_rate = 1 # for demonstration purposes\n",
    "\n",
    "def process_label(label):\n",
    "        label_path = Path(label)\n",
    "        if not label_path.exists():\n",
    "            logging.warning(f\"Label folder not found: {label_path}\")\n",
    "            return\n",
    "\n",
    "        for session_name in os.listdir(label_path):\n",
    "            session_path = os.path.join(label_path, session_name)\n",
    "            if not os.path.isdir(session_path):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                process_session(session_path, label, output_dir, frame_rate)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing session '{session_path}': {e}\")\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.map(process_label, target_extraction_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_file</th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>sensor_idx</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>accel_x</th>\n",
       "      <th>accel_y</th>\n",
       "      <th>accel_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frame_0000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.384450</td>\n",
       "      <td>0.453337</td>\n",
       "      <td>0.583412</td>\n",
       "      <td>-0.05100</td>\n",
       "      <td>7.07805</td>\n",
       "      <td>-7.16805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frame_0001.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>-0.007425</td>\n",
       "      <td>-0.029288</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>-0.31200</td>\n",
       "      <td>7.41105</td>\n",
       "      <td>-6.30105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame_0002.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>-0.036162</td>\n",
       "      <td>-0.098587</td>\n",
       "      <td>-0.021588</td>\n",
       "      <td>-0.23700</td>\n",
       "      <td>7.63905</td>\n",
       "      <td>-5.96805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frame_0003.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>297</td>\n",
       "      <td>0.049087</td>\n",
       "      <td>-0.113437</td>\n",
       "      <td>-0.003437</td>\n",
       "      <td>-0.54900</td>\n",
       "      <td>7.70595</td>\n",
       "      <td>-5.63295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frame_0004.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>396</td>\n",
       "      <td>-0.060638</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.007150</td>\n",
       "      <td>-0.49095</td>\n",
       "      <td>7.80195</td>\n",
       "      <td>-5.57295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       frame_file  frame_idx  sensor_idx    gyro_x    gyro_y    gyro_z  \\\n",
       "0  frame_0000.jpg          0           0 -0.384450  0.453337  0.583412   \n",
       "1  frame_0001.jpg          1          99 -0.007425 -0.029288  0.002887   \n",
       "2  frame_0002.jpg          2         198 -0.036162 -0.098587 -0.021588   \n",
       "3  frame_0003.jpg          3         297  0.049087 -0.113437 -0.003437   \n",
       "4  frame_0004.jpg          4         396 -0.060638  0.000550  0.007150   \n",
       "\n",
       "   accel_x  accel_y  accel_z  \n",
       "0 -0.05100  7.07805 -7.16805  \n",
       "1 -0.31200  7.41105 -6.30105  \n",
       "2 -0.23700  7.63905 -5.96805  \n",
       "3 -0.54900  7.70595 -5.63295  \n",
       "4 -0.49095  7.80195 -5.57295  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mapped_df = pd.read_csv(\"extracted_frames/workspace/good_pose/1/frame_sensor_mapping.csv\")\n",
    "mapped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "DATA_DIR = \"extracted_frames/workspace\"\n",
    "DATA_COLS = [\"gyro_x\", \"gyro_y\", \"gyro_z\", \"accel_x\", \"accel_y\", \"accel_z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.src.engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtfa\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21maugment_image\u001b[39m(img):\n\u001b[0;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    Apply enhanced data augmentation to a single image.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m        np.ndarray: Augmented image as a NumPy array.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\obada\\Desktop\\HoldWise Dataset\\myenv\\lib\\site-packages\\tensorflow_addons\\__init__.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m _check_tf_version()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Local project imports\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callbacks\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m image\n",
      "File \u001b[1;32mc:\\Users\\obada\\Desktop\\HoldWise Dataset\\myenv\\lib\\site-packages\\tensorflow_addons\\activations\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Additional activation functions.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgelu\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gelu\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhardshrink\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hardshrink\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlisht\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lisht\n",
      "File \u001b[1;32mc:\\Users\\obada\\Desktop\\HoldWise Dataset\\myenv\\lib\\site-packages\\tensorflow_addons\\activations\\gelu.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorLike\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mregister_keras_serializable(package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddons\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgelu\u001b[39m(x: TensorLike, approximate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gaussian Error Linear Unit.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    Computes gaussian error linear:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m        A `Tensor`. Has the same type as `x`.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\obada\\Desktop\\HoldWise Dataset\\myenv\\lib\\site-packages\\tensorflow_addons\\utils\\types.py:29\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# TODO: Remove once https://github.com/tensorflow/tensorflow/issues/44613 is resolved\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Version(tf\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mrelease \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.13\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrelease:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# New versions of Keras require importing from `keras.src` when\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# importing internal symbols.\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m Version(tf\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mrelease \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrelease:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.src.engine'"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "# ModuleNotFoundError: No module named 'keras.src.engine'Cell Execution Error\n",
    "\n",
    "def augment_image(img):\n",
    "    \"\"\"\n",
    "    Apply enhanced data augmentation to a single image.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image as a NumPy array.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Augmented image as a NumPy array.\n",
    "    \"\"\"\n",
    "    img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "\n",
    "    # Basic augmentations\n",
    "    img_tensor = tf.image.random_flip_left_right(img_tensor)  # Random horizontal flip\n",
    "    img_tensor = tf.image.random_flip_up_down(img_tensor)  # Random vertical flip\n",
    "    img_tensor = tf.image.random_brightness(img_tensor, max_delta=0.2)  # Random brightness\n",
    "    img_tensor = tf.image.random_contrast(img_tensor, lower=0.8, upper=1.2)  # Random contrast\n",
    "\n",
    "    # Rotation\n",
    "    angle = tf.random.uniform([], minval=-15, maxval=15, dtype=tf.float32)  # Random rotation (-15° to +15°)\n",
    "    img_tensor = tfa.image.rotate(img_tensor, angles=tf.constant(angle), interpolation='BILINEAR')\n",
    "\n",
    "    # Shear Transformation\n",
    "    img_tensor = tfa.image.shear_x(img_tensor, level=tf.random.uniform([], -0.3, 0.3), replace_value=0)\n",
    "    img_tensor = tfa.image.shear_y(img_tensor, level=tf.random.uniform([], -0.3, 0.3), replace_value=0)\n",
    "\n",
    "    # Scaling and Cropping\n",
    "    img_tensor = tf.image.resize_with_crop_or_pad(img_tensor, IMAGE_SIZE[0] + 20, IMAGE_SIZE[1] + 20)  # Add padding\n",
    "    img_tensor = tf.image.random_crop(img_tensor, size=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))  # Random crop\n",
    "\n",
    "    # Color Adjustments\n",
    "    img_tensor = tf.image.random_hue(img_tensor, max_delta=0.05)  # Adjust hue\n",
    "    img_tensor = tf.image.random_saturation(img_tensor, lower=0.8, upper=1.2)  # Adjust saturation\n",
    "\n",
    "    # Clip values to valid range\n",
    "    img_tensor = tf.clip_by_value(img_tensor, 0.0, 1.0)  # Clip values between 0 and 1 (normalized range)\n",
    "\n",
    "    return img_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, min_frames_per_session=1, augmentations_per_image=3):\n",
    "    \"\"\"\n",
    "    Loads images, sensor data, and labels from the dataset directory, with data augmentation.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Path to the dataset directory.\n",
    "        min_frames_per_session (int): Minimum number of frames required to process a session.\n",
    "        augmentations_per_image (int): Number of augmented images to generate per original image.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (images, sensors, labels)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    sensors = []\n",
    "    labels = []\n",
    "\n",
    "    for label_folder in [\"good_pose\", \"bad_pose\"]:\n",
    "        label_path = os.path.join(data_dir, label_folder)\n",
    "        if not os.path.exists(label_path):\n",
    "            logging.warning(f\"Label folder not found: {label_path}\")\n",
    "            continue\n",
    "\n",
    "        # Loop through each session folder\n",
    "        session_folders = [f for f in os.listdir(label_path) if os.path.isdir(os.path.join(label_path, f))]\n",
    "        for session in session_folders:\n",
    "            session_path = os.path.join(label_path, session)\n",
    "\n",
    "            # Find the sensor mapping CSV\n",
    "            csv_file = os.path.join(session_path, \"frame_sensor_mapping.csv\")\n",
    "            if not os.path.exists(csv_file):\n",
    "                logging.warning(f\"Sensor mapping CSV not found: {csv_file}\")\n",
    "                continue\n",
    "\n",
    "            # Load the sensor data from CSV\n",
    "            df = pd.read_csv(csv_file)\n",
    "            session_images = []\n",
    "            session_sensors = []\n",
    "            session_labels = []\n",
    "\n",
    "            # Get all available frame filenames in the session directory\n",
    "            available_frames = {os.path.basename(f) for f in os.listdir(session_path) if f.endswith('.jpg')}\n",
    "            logging.debug(f\"Available frames in {session_path}: {available_frames}\")\n",
    "\n",
    "            for _, row in df.iterrows():\n",
    "                frame_file_name = row[\"frame_file\"]\n",
    "                if frame_file_name not in available_frames:\n",
    "                    logging.warning(f\"Frame file not found: {frame_file_name}\")\n",
    "                    continue\n",
    "\n",
    "                frame_file_path = os.path.join(session_path, frame_file_name)\n",
    "                try:\n",
    "                    # Load and preprocess image\n",
    "                    img = preprocessing.image.load_img(frame_file_path, target_size=IMAGE_SIZE)\n",
    "                    img = preprocessing.image.img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "                    # Apply augmentations\n",
    "                    augmented_imgs = [img] + [augment_image(img) for _ in range(augmentations_per_image)]\n",
    "\n",
    "                    # Load sensor data\n",
    "                    sensor_features = np.array([\n",
    "                        row[\"gyro_x\"], row[\"gyro_y\"], row[\"gyro_z\"],\n",
    "                        row[\"accel_x\"], row[\"accel_y\"], row[\"accel_z\"]\n",
    "                    ])\n",
    "\n",
    "                    # Append data\n",
    "                    for augmented_img in augmented_imgs:\n",
    "                        session_images.append(augmented_img)\n",
    "                        session_sensors.append(sensor_features)\n",
    "                        session_labels.append(1 if label_folder == \"good_pose\" else 0)\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing frame {frame_file_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # Check if session has enough frames\n",
    "            if len(session_images) < min_frames_per_session:\n",
    "                logging.warning(f\"Session skipped due to insufficient frames: {session_path}\")\n",
    "                continue\n",
    "\n",
    "            # Add session data to global lists\n",
    "            images.extend(session_images)\n",
    "            sensors.extend(session_sensors)\n",
    "            labels.extend(session_labels)\n",
    "\n",
    "    images = np.array(images, dtype=np.float32)\n",
    "    sensors = np.array(sensors, dtype=np.float32)\n",
    "    labels = utils.to_categorical(np.array(labels, dtype=np.int32), num_classes=2)\n",
    "\n",
    "    logging.info(f\"Loaded {len(labels)} samples (including augmented) from {data_dir}.\")\n",
    "    return images, sensors, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocessing.image.load_img('extracted_frames/workspace/bad_pose/10/frame_0000.jpg', target_size=IMAGE_SIZE)\n",
    "# print(img)\n",
    "img_array = preprocessing.image.img_to_array(img)\n",
    "# print(img_array)\n",
    "augmented_imgs = [img_array] + [augment_image(img) for _ in range(3)]\n",
    "\n",
    "# store teh augmented images in a directory\n",
    "augmented_dir = \"augmented_images\"\n",
    "os.makedirs(augmented_dir, exist_ok=True)\n",
    "for i, img in enumerate(augmented_imgs):\n",
    "    img_path = os.path.join(augmented_dir, f\"augmented_{i}.jpg\")\n",
    "    img_pil = preprocessing.image.array_to_img(img)\n",
    "    img_pil.save(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(images, sensors, labels, validation_split=0.2, test_split=0.1):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training, testing, and validation sets.\n",
    "    \n",
    "    Args:\n",
    "        images (np.ndarray): Array of image data.\n",
    "        sensors (np.ndarray): Array of sensor data.\n",
    "        labels (np.ndarray): Array of labels.\n",
    "        validation_split (float): Proportion of the data to use for validation.\n",
    "        test_split (float): Proportion of the data to use for testing.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple: (X_img_train, X_img_val, X_img_test, \n",
    "                X_sensor_train, X_sensor_val, X_sensor_test, \n",
    "                y_train, y_val, y_test)\n",
    "    \"\"\"\n",
    "    dataset_size = len(images)\n",
    "    test_size = int(dataset_size * test_split)\n",
    "    val_size = int(dataset_size * validation_split)\n",
    "    train_size = dataset_size - test_size - val_size\n",
    "\n",
    "    # Shuffle indices\n",
    "    indices = np.arange(dataset_size)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Split indices\n",
    "    test_indices = indices[:test_size]\n",
    "    val_indices = indices[test_size:test_size + val_size]\n",
    "    train_indices = indices[test_size + val_size:]\n",
    "\n",
    "    # Slice data\n",
    "    X_img_train = images[train_indices]\n",
    "    X_img_val = images[val_indices]\n",
    "    X_img_test = images[test_indices]\n",
    "    X_sensor_train = sensors[train_indices]\n",
    "    X_sensor_val = sensors[val_indices]\n",
    "    X_sensor_test = sensors[test_indices]\n",
    "    y_train = labels[train_indices]\n",
    "    y_val = labels[val_indices]\n",
    "    y_test = labels[test_indices]\n",
    "\n",
    "    return (X_img_train, X_img_val, X_img_test, \n",
    "            X_sensor_train, X_sensor_val, X_sensor_test, \n",
    "            y_train, y_val, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 17:13:00,135 - WARNING - Sensor mapping CSV not found: extracted_frames/workspace\\good_pose\\11\\frame_sensor_mapping.csv\n",
      "2025-01-08 17:13:54,942 - WARNING - Sensor mapping CSV not found: extracted_frames/workspace\\bad_pose\\10\\frame_sensor_mapping.csv\n",
      "2025-01-08 17:14:32,042 - WARNING - Sensor mapping CSV not found: extracted_frames/workspace\\bad_pose\\9\\frame_sensor_mapping.csv\n",
      "2025-01-08 17:16:19,867 - INFO - Loaded 15916 samples (including augmented) from extracted_frames/workspace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: Images - (15916, 224, 224, 3), Sensors - (15916, 6), Labels - (15916, 2)\n"
     ]
    }
   ],
   "source": [
    "images, sensors, labels = load_data(DATA_DIR)\n",
    "# Split data using custom splitting logic\n",
    "\n",
    "print(\n",
    "    f\"Loaded data: Images - {images.shape}, Sensors - {sensors.shape}, Labels - {labels.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image training data shape: (2787, 224, 224, 3)\n",
      "Sensor training data shape: (2787, 6)\n",
      "Label training data shape: (2787, 2)\n",
      "Image validation data shape: (795, 224, 224, 3)\n",
      "Sensor validation data shape: (795, 6)\n",
      "Label validation data shape: (795, 2)\n",
      "Image testing data shape: (397, 224, 224, 3)\n",
      "Sensor testing data shape: (397, 6)\n",
      "Label testing data shape: (397, 2)\n"
     ]
    }
   ],
   "source": [
    "X_img_train, X_img_val, X_img_test, X_sensor_train, X_sensor_val, X_sensor_test, y_train, y_val, y_test = split_data(\n",
    "    images, sensors, labels, validation_split=0.2, test_split=0.1\n",
    ")\n",
    "\n",
    "# Check shapes\n",
    "print(\"Image training data shape:\", X_img_train.shape)\n",
    "print(\"Sensor training data shape:\", X_sensor_train.shape)\n",
    "print(\"Label training data shape:\", y_train.shape)\n",
    "print(\"Image validation data shape:\", X_img_val.shape)\n",
    "print(\"Sensor validation data shape:\", X_sensor_val.shape)\n",
    "print(\"Label validation data shape:\", y_val.shape)\n",
    "print(\"Image testing data shape:\", X_img_test.shape)\n",
    "print(\"Sensor testing data shape:\", X_sensor_test.shape)\n",
    "print(\"Label testing data shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.75686276, 0.7529412 , 0.7372549 ],\n",
       "        [0.7529412 , 0.7490196 , 0.73333335],\n",
       "        [0.7607843 , 0.74509805, 0.73333335],\n",
       "        ...,\n",
       "        [0.8117647 , 0.80784315, 0.7921569 ],\n",
       "        [0.8156863 , 0.8117647 , 0.79607844],\n",
       "        [0.81960785, 0.8156863 , 0.8       ]],\n",
       "\n",
       "       [[0.76862746, 0.7529412 , 0.7411765 ],\n",
       "        [0.76862746, 0.7529412 , 0.7411765 ],\n",
       "        [0.76862746, 0.7529412 , 0.7411765 ],\n",
       "        ...,\n",
       "        [0.81960785, 0.8156863 , 0.8       ],\n",
       "        [0.8235294 , 0.81960785, 0.8039216 ],\n",
       "        [0.81960785, 0.8156863 , 0.8       ]],\n",
       "\n",
       "       [[0.77254903, 0.7529412 , 0.7411765 ],\n",
       "        [0.77254903, 0.7529412 , 0.7411765 ],\n",
       "        [0.76862746, 0.75686276, 0.7372549 ],\n",
       "        ...,\n",
       "        [0.83137256, 0.8156863 , 0.8039216 ],\n",
       "        [0.8235294 , 0.81960785, 0.8039216 ],\n",
       "        [0.8235294 , 0.81960785, 0.8039216 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.16862746, 0.17254902, 0.1882353 ],\n",
       "        [0.16078432, 0.16470589, 0.18039216],\n",
       "        [0.16470589, 0.16862746, 0.18431373],\n",
       "        ...,\n",
       "        [0.18039216, 0.18431373, 0.20392157],\n",
       "        [0.19215687, 0.19607843, 0.21176471],\n",
       "        [0.1882353 , 0.19215687, 0.20784314]],\n",
       "\n",
       "       [[0.16862746, 0.16862746, 0.1764706 ],\n",
       "        [0.16078432, 0.16470589, 0.17254902],\n",
       "        [0.16470589, 0.16862746, 0.1764706 ],\n",
       "        ...,\n",
       "        [0.18039216, 0.18431373, 0.2       ],\n",
       "        [0.19215687, 0.19607843, 0.21176471],\n",
       "        [0.18039216, 0.18431373, 0.2       ]],\n",
       "\n",
       "       [[0.17254902, 0.17254902, 0.18039216],\n",
       "        [0.16078432, 0.16078432, 0.16862746],\n",
       "        [0.15686275, 0.16078432, 0.16862746],\n",
       "        ...,\n",
       "        [0.1882353 , 0.19215687, 0.2       ],\n",
       "        [0.1882353 , 0.19215687, 0.2       ],\n",
       "        [0.19215687, 0.19607843, 0.20392157]]], dtype=float32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "X_img_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obada\\AppData\\Local\\Temp\\ipykernel_13032\\2539727540.py:3: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = applications.MobileNetV2(weights='imagenet', include_top=False, input_tensor=image_input)\n"
     ]
    }
   ],
   "source": [
    "# Image input\n",
    "image_input = layers.Input(shape=(224, 224, 3))\n",
    "base_model = applications.MobileNetV2(weights='imagenet', include_top=False, input_tensor=image_input)\n",
    "image_features = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "# Sensor input\n",
    "sensor_input = layers.Input(shape=(6,))  # 3 gyroscope + 3 accelerometer features\n",
    "sensor_features = layers.Dense(64, activation='relu')(sensor_input)\n",
    "\n",
    "# Combine features\n",
    "combined = layers.concatenate([image_features, sensor_features])\n",
    "combined = layers.Dense(128, activation='relu')(combined)\n",
    "output = layers.Dense(2, activation='softmax')(combined)\n",
    "\n",
    "model = models.Model(inputs=[image_input, sensor_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
